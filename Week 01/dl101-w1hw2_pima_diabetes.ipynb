{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Imports\nimport pandas as pd\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping","metadata":{"execution":{"iopub.status.busy":"2023-06-12T23:42:06.727806Z","iopub.execute_input":"2023-06-12T23:42:06.728527Z","iopub.status.idle":"2023-06-12T23:42:06.734428Z","shell.execute_reply.started":"2023-06-12T23:42:06.728486Z","shell.execute_reply":"2023-06-12T23:42:06.733288Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Create dataframe\ndf = pd.read_csv('/kaggle/input/pima-indians-diabetes-database/diabetes.csv')\nprint(df)","metadata":{"execution":{"iopub.status.busy":"2023-06-12T23:40:33.505970Z","iopub.execute_input":"2023-06-12T23:40:33.506864Z","iopub.status.idle":"2023-06-12T23:40:33.560942Z","shell.execute_reply.started":"2023-06-12T23:40:33.506813Z","shell.execute_reply":"2023-06-12T23:40:33.559584Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n0              6      148             72             35        0  33.6   \n1              1       85             66             29        0  26.6   \n2              8      183             64              0        0  23.3   \n3              1       89             66             23       94  28.1   \n4              0      137             40             35      168  43.1   \n..           ...      ...            ...            ...      ...   ...   \n763           10      101             76             48      180  32.9   \n764            2      122             70             27        0  36.8   \n765            5      121             72             23      112  26.2   \n766            1      126             60              0        0  30.1   \n767            1       93             70             31        0  30.4   \n\n     DiabetesPedigreeFunction  Age  Outcome  \n0                       0.627   50        1  \n1                       0.351   31        0  \n2                       0.672   32        1  \n3                       0.167   21        0  \n4                       2.288   33        1  \n..                        ...  ...      ...  \n763                     0.171   63        0  \n764                     0.340   27        0  \n765                     0.245   30        0  \n766                     0.349   47        1  \n767                     0.315   23        0  \n\n[768 rows x 9 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Separate the features and labels\nX = df.drop('Outcome', axis=1)\ny = df['Outcome']","metadata":{"execution":{"iopub.status.busy":"2023-06-12T23:40:33.562413Z","iopub.execute_input":"2023-06-12T23:40:33.562828Z","iopub.status.idle":"2023-06-12T23:40:33.574067Z","shell.execute_reply.started":"2023-06-12T23:40:33.562792Z","shell.execute_reply":"2023-06-12T23:40:33.572579Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Perform train-test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=32)\n\n# Perform train-validation split\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15, random_state=32)","metadata":{"execution":{"iopub.status.busy":"2023-06-12T23:42:25.823706Z","iopub.execute_input":"2023-06-12T23:42:25.824113Z","iopub.status.idle":"2023-06-12T23:42:25.834582Z","shell.execute_reply.started":"2023-06-12T23:42:25.824085Z","shell.execute_reply":"2023-06-12T23:42:25.833330Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Standardize the features\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-06-12T23:42:28.112037Z","iopub.execute_input":"2023-06-12T23:42:28.112651Z","iopub.status.idle":"2023-06-12T23:42:28.123169Z","shell.execute_reply.started":"2023-06-12T23:42:28.112618Z","shell.execute_reply":"2023-06-12T23:42:28.122232Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Build the MLP model\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Dense(units=4, activation='relu', input_shape=(X_train.shape[1],)),\n    tf.keras.layers.Dense(units=2, activation='sigmoid')\n])\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n# Define the learning rate reduction callback\nlr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n    monitor='val_loss',    # Monitor validation loss for learning rate reduction\n    factor=0.5,            # Reduce learning rate by a factor\n    patience=10,            # Number of epochs with no improvement after which learning rate will be reduced\n    min_lr=1e-6            # Minimum learning rate\n)\n\n# Define the model checkpoint callback to save the best model\ncheckpoint_callback = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)\n\n# Define the early stopping callback to stop training if validation loss does not improve\nearly_stopping_callback = EarlyStopping(monitor='val_loss', patience=5)\n\n# Train the model with the learning rate reduction callback\nmodel.fit(X_train, y_train, validation_data=(X_val,y_val), epochs=20, callbacks=[lr_callback,checkpoint_callback,early_stopping_callback])\n\n# Evaluate the model\nbest_model = tf.keras.models.load_model('best_model.h5')\nloss, accuracy = best_model.evaluate(X_test, y_test)\nprint('Loss = {} \\nAccuracy = {}'.format(loss, accuracy*100))","metadata":{"execution":{"iopub.status.busy":"2023-06-12T23:42:35.894720Z","iopub.execute_input":"2023-06-12T23:42:35.895237Z","iopub.status.idle":"2023-06-12T23:42:38.348521Z","shell.execute_reply.started":"2023-06-12T23:42:35.895194Z","shell.execute_reply":"2023-06-12T23:42:38.347177Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Epoch 1/20\n18/18 [==============================] - 1s 15ms/step - loss: 0.6867 - accuracy: 0.5812 - val_loss: 12.7729 - val_accuracy: 0.6429 - lr: 0.0010\nEpoch 2/20\n18/18 [==============================] - 0s 5ms/step - loss: 0.6660 - accuracy: 0.6083 - val_loss: 10.7604 - val_accuracy: 0.6429 - lr: 0.0010\nEpoch 3/20\n18/18 [==============================] - 0s 5ms/step - loss: 0.6502 - accuracy: 0.6227 - val_loss: 8.9848 - val_accuracy: 0.6429 - lr: 0.0010\nEpoch 4/20\n18/18 [==============================] - 0s 4ms/step - loss: 0.6349 - accuracy: 0.6408 - val_loss: 7.4911 - val_accuracy: 0.6531 - lr: 0.0010\nEpoch 5/20\n18/18 [==============================] - 0s 5ms/step - loss: 0.6225 - accuracy: 0.6516 - val_loss: 6.1689 - val_accuracy: 0.6633 - lr: 0.0010\nEpoch 6/20\n18/18 [==============================] - 0s 5ms/step - loss: 0.6108 - accuracy: 0.6552 - val_loss: 5.1034 - val_accuracy: 0.6837 - lr: 0.0010\nEpoch 7/20\n18/18 [==============================] - 0s 5ms/step - loss: 0.6006 - accuracy: 0.6625 - val_loss: 4.3041 - val_accuracy: 0.6429 - lr: 0.0010\nEpoch 8/20\n18/18 [==============================] - 0s 5ms/step - loss: 0.5914 - accuracy: 0.6697 - val_loss: 3.8113 - val_accuracy: 0.6122 - lr: 0.0010\nEpoch 9/20\n18/18 [==============================] - 0s 6ms/step - loss: 0.5832 - accuracy: 0.6697 - val_loss: 3.5179 - val_accuracy: 0.5918 - lr: 0.0010\nEpoch 10/20\n18/18 [==============================] - 0s 5ms/step - loss: 0.5757 - accuracy: 0.6733 - val_loss: 3.3929 - val_accuracy: 0.5612 - lr: 0.0010\nEpoch 11/20\n18/18 [==============================] - 0s 4ms/step - loss: 0.5688 - accuracy: 0.6787 - val_loss: 3.5540 - val_accuracy: 0.5306 - lr: 0.0010\nEpoch 12/20\n18/18 [==============================] - 0s 4ms/step - loss: 0.5620 - accuracy: 0.6841 - val_loss: 3.8658 - val_accuracy: 0.5306 - lr: 0.0010\nEpoch 13/20\n18/18 [==============================] - 0s 5ms/step - loss: 0.5559 - accuracy: 0.6859 - val_loss: 4.3840 - val_accuracy: 0.4898 - lr: 0.0010\nEpoch 14/20\n18/18 [==============================] - 0s 4ms/step - loss: 0.5499 - accuracy: 0.6841 - val_loss: 5.0875 - val_accuracy: 0.5000 - lr: 0.0010\nEpoch 15/20\n18/18 [==============================] - 0s 4ms/step - loss: 0.5447 - accuracy: 0.6913 - val_loss: 5.8393 - val_accuracy: 0.4898 - lr: 0.0010\n4/4 [==============================] - 0s 3ms/step - loss: 0.5715 - accuracy: 0.6897\nLoss = 0.5714818835258484 \nAccuracy = 68.96551847457886\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}