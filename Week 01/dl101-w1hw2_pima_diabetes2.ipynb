{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Imports\nimport pandas as pd\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping","metadata":{"execution":{"iopub.status.busy":"2023-06-13T05:29:35.284946Z","iopub.execute_input":"2023-06-13T05:29:35.285365Z","iopub.status.idle":"2023-06-13T05:29:35.292211Z","shell.execute_reply.started":"2023-06-13T05:29:35.285333Z","shell.execute_reply":"2023-06-13T05:29:35.291023Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Create dataframe\ndf = pd.read_csv('/kaggle/input/pima-indians-diabetes-database/diabetes.csv')\nprint(df)","metadata":{"execution":{"iopub.status.busy":"2023-06-13T05:29:39.740051Z","iopub.execute_input":"2023-06-13T05:29:39.740446Z","iopub.status.idle":"2023-06-13T05:29:39.762150Z","shell.execute_reply.started":"2023-06-13T05:29:39.740417Z","shell.execute_reply":"2023-06-13T05:29:39.761018Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n0              6      148             72             35        0  33.6   \n1              1       85             66             29        0  26.6   \n2              8      183             64              0        0  23.3   \n3              1       89             66             23       94  28.1   \n4              0      137             40             35      168  43.1   \n..           ...      ...            ...            ...      ...   ...   \n763           10      101             76             48      180  32.9   \n764            2      122             70             27        0  36.8   \n765            5      121             72             23      112  26.2   \n766            1      126             60              0        0  30.1   \n767            1       93             70             31        0  30.4   \n\n     DiabetesPedigreeFunction  Age  Outcome  \n0                       0.627   50        1  \n1                       0.351   31        0  \n2                       0.672   32        1  \n3                       0.167   21        0  \n4                       2.288   33        1  \n..                        ...  ...      ...  \n763                     0.171   63        0  \n764                     0.340   27        0  \n765                     0.245   30        0  \n766                     0.349   47        1  \n767                     0.315   23        0  \n\n[768 rows x 9 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Separate the features and labels\nX = df.drop('Outcome', axis=1)\ny = df['Outcome']","metadata":{"execution":{"iopub.status.busy":"2023-06-13T05:26:25.402646Z","iopub.execute_input":"2023-06-13T05:26:25.402994Z","iopub.status.idle":"2023-06-13T05:26:25.411415Z","shell.execute_reply.started":"2023-06-13T05:26:25.402966Z","shell.execute_reply":"2023-06-13T05:26:25.410081Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Perform train-test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=32)\n\n# Perform train-validation split\n#X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15, random_state=32)","metadata":{"execution":{"iopub.status.busy":"2023-06-13T05:27:23.805408Z","iopub.execute_input":"2023-06-13T05:27:23.805795Z","iopub.status.idle":"2023-06-13T05:27:23.814844Z","shell.execute_reply.started":"2023-06-13T05:27:23.805758Z","shell.execute_reply":"2023-06-13T05:27:23.813481Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Standardize the features\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-06-13T05:27:26.666517Z","iopub.execute_input":"2023-06-13T05:27:26.666932Z","iopub.status.idle":"2023-06-13T05:27:26.679858Z","shell.execute_reply.started":"2023-06-13T05:27:26.666899Z","shell.execute_reply":"2023-06-13T05:27:26.678368Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Build the MLP model\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Dense(units=4, activation='relu', input_shape=(X_train.shape[1],)),\n    tf.keras.layers.Dense(units=2, activation='sigmoid')\n])\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n\n\n# Train the model with the learning rate reduction callback\nmodel.fit(X_train, y_train, epochs=40)\n\n# Evaluate the model\n#best_model = tf.keras.models.load_model('best_model.h5')\nloss, accuracy = model.evaluate(X_test, y_test)\nprint('Loss = {} \\nAccuracy = {}'.format(loss, accuracy*100))","metadata":{"execution":{"iopub.status.busy":"2023-06-13T05:41:34.318422Z","iopub.execute_input":"2023-06-13T05:41:34.318852Z","iopub.status.idle":"2023-06-13T05:41:36.637638Z","shell.execute_reply.started":"2023-06-13T05:41:34.318797Z","shell.execute_reply":"2023-06-13T05:41:36.636774Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Epoch 1/40\n17/17 [==============================] - 1s 2ms/step - loss: 0.9274 - accuracy: 0.4209\nEpoch 2/40\n17/17 [==============================] - 0s 2ms/step - loss: 0.8817 - accuracy: 0.4507\nEpoch 3/40\n17/17 [==============================] - 0s 2ms/step - loss: 0.8433 - accuracy: 0.4730\nEpoch 4/40\n17/17 [==============================] - 0s 2ms/step - loss: 0.8073 - accuracy: 0.5196\nEpoch 5/40\n17/17 [==============================] - 0s 2ms/step - loss: 0.7785 - accuracy: 0.5475\nEpoch 6/40\n17/17 [==============================] - 0s 2ms/step - loss: 0.7520 - accuracy: 0.5717\nEpoch 7/40\n17/17 [==============================] - 0s 2ms/step - loss: 0.7296 - accuracy: 0.5940\nEpoch 8/40\n17/17 [==============================] - 0s 2ms/step - loss: 0.7094 - accuracy: 0.6238\nEpoch 9/40\n17/17 [==============================] - 0s 2ms/step - loss: 0.6909 - accuracy: 0.6294\nEpoch 10/40\n17/17 [==============================] - 0s 2ms/step - loss: 0.6748 - accuracy: 0.6369\nEpoch 11/40\n17/17 [==============================] - 0s 2ms/step - loss: 0.6605 - accuracy: 0.6462\nEpoch 12/40\n17/17 [==============================] - 0s 2ms/step - loss: 0.6472 - accuracy: 0.6480\nEpoch 13/40\n17/17 [==============================] - 0s 2ms/step - loss: 0.6362 - accuracy: 0.6499\nEpoch 14/40\n17/17 [==============================] - 0s 2ms/step - loss: 0.6261 - accuracy: 0.6518\nEpoch 15/40\n17/17 [==============================] - 0s 2ms/step - loss: 0.6169 - accuracy: 0.6592\nEpoch 16/40\n17/17 [==============================] - 0s 2ms/step - loss: 0.6081 - accuracy: 0.6704\nEpoch 17/40\n17/17 [==============================] - 0s 2ms/step - loss: 0.6004 - accuracy: 0.6741\nEpoch 18/40\n17/17 [==============================] - 0s 2ms/step - loss: 0.5928 - accuracy: 0.6760\nEpoch 19/40\n17/17 [==============================] - 0s 2ms/step - loss: 0.5862 - accuracy: 0.6834\nEpoch 20/40\n17/17 [==============================] - 0s 2ms/step - loss: 0.5798 - accuracy: 0.6909\nEpoch 21/40\n17/17 [==============================] - 0s 2ms/step - loss: 0.5739 - accuracy: 0.6909\nEpoch 22/40\n17/17 [==============================] - 0s 2ms/step - loss: 0.5681 - accuracy: 0.6965\nEpoch 23/40\n17/17 [==============================] - 0s 2ms/step - loss: 0.5633 - accuracy: 0.7076\nEpoch 24/40\n17/17 [==============================] - 0s 2ms/step - loss: 0.5582 - accuracy: 0.7058\nEpoch 25/40\n17/17 [==============================] - 0s 2ms/step - loss: 0.5538 - accuracy: 0.7095\nEpoch 26/40\n17/17 [==============================] - 0s 2ms/step - loss: 0.5493 - accuracy: 0.7132\nEpoch 27/40\n17/17 [==============================] - 0s 2ms/step - loss: 0.5453 - accuracy: 0.7169\nEpoch 28/40\n17/17 [==============================] - 0s 2ms/step - loss: 0.5413 - accuracy: 0.7207\nEpoch 29/40\n17/17 [==============================] - 0s 2ms/step - loss: 0.5381 - accuracy: 0.7151\nEpoch 30/40\n17/17 [==============================] - 0s 2ms/step - loss: 0.5343 - accuracy: 0.7169\nEpoch 31/40\n17/17 [==============================] - 0s 2ms/step - loss: 0.5314 - accuracy: 0.7225\nEpoch 32/40\n17/17 [==============================] - 0s 2ms/step - loss: 0.5281 - accuracy: 0.7281\nEpoch 33/40\n17/17 [==============================] - 0s 2ms/step - loss: 0.5253 - accuracy: 0.7337\nEpoch 34/40\n17/17 [==============================] - 0s 2ms/step - loss: 0.5228 - accuracy: 0.7356\nEpoch 35/40\n17/17 [==============================] - 0s 2ms/step - loss: 0.5198 - accuracy: 0.7393\nEpoch 36/40\n17/17 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.7356\nEpoch 37/40\n17/17 [==============================] - 0s 2ms/step - loss: 0.5153 - accuracy: 0.7374\nEpoch 38/40\n17/17 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.7393\nEpoch 39/40\n17/17 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.7430\nEpoch 40/40\n17/17 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.7449\n8/8 [==============================] - 0s 2ms/step - loss: 0.4881 - accuracy: 0.7835\nLoss = 0.48814061284065247 \nAccuracy = 78.35497856140137\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**When with validation**","metadata":{}},{"cell_type":"code","source":"# Define the learning rate reduction callback\nlr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n    monitor='val_loss',    # Monitor validation loss for learning rate reduction\n    factor=0.5,            # Reduce learning rate by a factor\n    patience=10,            # Number of epochs with no improvement after which learning rate will be reduced\n    min_lr=1e-6            # Minimum learning rate\n)\n\n# Define the model checkpoint callback to save the best model\ncheckpoint_callback = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)\n\n# Define the early stopping callback to stop training if validation loss does not improve\nearly_stopping_callback = EarlyStopping(monitor='val_loss', patience=5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}